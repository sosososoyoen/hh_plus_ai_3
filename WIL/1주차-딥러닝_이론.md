# 1주차 WIL

이번 글에서는 딥러닝의 개념과 선형회귀에 대해서 공부한 것들에 대해 간략하게 적어보려고 한다.

정기 모임에서 배운 것 + 사전 지급 강의에서 배운 것 + 내가 따로 찾아보면서 공부한 것들을 내 표현대로 정리해보았다.

![](https://velog.velcdn.com/images/soonmac/post/ca418865-df21-48b6-96fe-be48fdee5014/image.png)

이미지 출처 : https://www.google.com/url?sa=i&url=https%3A%2F%2Fsiddhithakkar.com%2F2020%2F02%2F24%2Fai-vs-ml-vs-dl-whats-the-difference%2F&psig=AOvVaw2vhsnHsDYx9QqUTuL8KdDV&ust=1742794094959000&source=images&cd=vfe&opi=89978449&ved=0CBcQjhxqFwoTCKDP9Y28n4wDFQAAAAAdAAAAABAE

# 1. 딥러닝의 개념

## 인공지능, 머신러닝, 딥러닝의 차이점

- 인공지능 : 인간의 지능을 모방하여 문제를 해결하는 기술. 규칙 기반부터 자율 학습까지 다양한 방식이 있음
- 머신러닝 : 데이터를 이용해 모델을 학습 → 예측, 결정
- 딥러닝 : 머신러닝의 하위 분야. 신경망을 여러층으로 쌓아서 데이터를 학습. 대규모 데이터, 복잡한 문제에 강함 (대신 학습에 비용이 많이 발생)

## 딥러닝의 개념

![](https://velog.velcdn.com/images/soonmac/post/8e26b4f3-7831-4c9e-af6b-269af5419814/image.png)

출처:https://ars.els-cdn.com/content/image/1-s2.0-S1746809422002270-gr1.jpg

- 인공신경망을 기반으로 한 머신 러닝의 한 분야
    - **인공신경망 : 인간의 두뇌를 수학적으로 모방한 것!**
- 인공신경망의 층을 쌓아올려서 데이터로부터 특징을 자동으로 학습하고, 이를 통해 복잡한 문제를 해결함
- 입력 데이터에서 중요한 패턴 추출 → 예측, 분류, 생성 등 다양한 작업 수행
    - 이 중요한 패턴은 컴퓨터 기준이라서 사람의 기준과 다름!
- 이미지, 자연어, 음성, 의료 다양한 분야에 쓰임

 
> 💡 사람의 뇌 구조를 따와서 컴퓨터에 적용시킨 느낌?!


## 머신러닝의 과정

- 태스크 정의 → 평가 지표 정의 → 최적화
    - **태스크 정의** : AI가 해결해야할 문제를 정의 - 입력과 예측값 출력.
    - **평가 지표 정의** : AI가 예측한 값과 실제 값(정답)을 비교해서 정확도를 계산하는 방식으로 정의 - 함수로 표현
    - **최적화** : 평가 지표가 가장 좋은 AI 모델을 찾기

## 🌟선형 회귀 (linear regression)

![](https://velog.velcdn.com/images/soonmac/post/cd4451b0-fd21-4e02-90e6-56c4b99c22e4/image.png)


출처 : https://blog.kakaocdn.net/dn/dkPQPp/btrgCGYXkSv/ScgHHGULTWFRY4HYrrY7h0/img.png

https://youtu.be/LZe94nm1lZg?si=VPzeHicu6uJRvCo1

- **✅ 머신러닝의 기본 작동 원리!**
- **알고 있는 데이터 값을 사용하여 모르는 데이터의 값을 예측하는 데이터 분석 기법**
- 그래프 위에 점이 우리가 알고 있는 데이터 값이고, 데이터 값들의 경향성을 선으로 그려낸 것
- 최적의 선을 찾기 위해 계속 방향을 수정해서 try (사람이랑 닮았죠?)
- 원인에 해당하는 변수 x (=독립 변수)
- 결과에 해당하는 변수 y (=종속 변수)
- 직선 그래프니까 f(x) = wx + b 이런 식으로 표현할 수 있음.

### 최적의 선을 찾기 위한 여정 - MSE(평균 제곱 오차)

- 최적의 선을 찾기 위해서는 우선 오차를 계산해야함.
- 여기서는 **오차의 제곱의 평균을 구해서** AI가 내놓은 예측 값과 실제 값의 오차를 계산하고 있다.

$$
l(f) = \frac{1}{N}\sum_{i=1}^N(f(x_i) - y_i)^2.
$$

- N : 데이터의 총 개수
- $f(x_i)$: 머신러닝 모델이 예측한 값
- $y_i$ :실제 값. 모델이 맞춰야할 정답
- $f(x_i) - y_i$ :  모델이 예측한 값과 실제 값의 차이 (= 오차)
- $(f(x_i) - y_i)^2$ : 제곱하는 이유 - 오차가 양수, 음수 상관없이 양수로 만들어서 평가하기 위해
- $\sum_{i=1}^N (f(x_i) - y_i)^2$ : 모든 데이터에서 발생한 오차를 다 더한다.
- $\frac{1}{N}$ : 평균을 내기 위해 데이터 포인트의 개수대로 나누기!

**(예시)**

- 실제 피규어 가격 $y_i$ = 100만 원
- 모델이 예측한 피규어 가격 $f(x_i)$= 120만 원
- 오차 = 120−100= 20 (만원)
- 오차 제곱 = 400

좋아.. 오차까지는 구하는 방법을 알았다. 이걸로 성능 평가도 할 수 있을 것 같다.

그러면 기울기를 수정해야하는데, 여기서는 **경사하강법**이라는 것을 배웠다.

## 경사하강법

![image.png](https://hwk0702.github.io/img/gradient.png)

출처 : https://hwk0702.github.io/img/gradient.png

1. 처음에는 모델 그래프의 직선인 $f(x) = wx + b$ 에서 기울기를 결정하는 **$w$와 $b$의 값을 랜덤하게 초기화**를 함.
2. 그런 다음, 오차를 계산하고 업데이트 방향을 결정함. 이 때 기울기(미분)를 사용해 업데이트 방향을 정함
3. 이렇게 기울기 값을 이용해 $w$와 $b$를 계속 수정하면서 오차가 점점 줄어드는 방향으로 이동함
4. 이 과정은 기울기가 거의 0에 가까워질 때까지 반복됨.
5. 오차가 최소로 되는 지점을 찾는 여정이라 할 수 있겠다

## 선형 회귀는 XOR 문제를 해결할 수 없다?!

- 단일 퍼셉트론 - 선형 분류(y = ax + b로 표시되는 선형(직선) 함수)
    - ⇒ XOR(베타적 논리합) 같은 비선형(곡선) 문제 해결 X

![](https://velog.velcdn.com/images/soonmac/post/94624c4e-8ce0-4bbf-8e9e-605a50f03d20/image.png)

선형 함수(선형적 = 직선 line)


![](https://velog.velcdn.com/images/soonmac/post/cf52cbbf-2d0f-4489-8780-63e821ed52c6/image.png)

- XOR 문제는 두 입력이 다를 때만 True(1)을 출력하기 때문에, 단일 퍼셉트론으로는 해결X
- BUT 다중 퍼셉트론은 은닉층을 통해 비선형성을 학습할 수 있어서 XOR 문제를 해결할 수 있음

## 🧠 퍼셉트론과 다층 퍼셉트론

### 퍼셉트론

![](https://velog.velcdn.com/images/soonmac/post/cefccf9e-5b44-4ec8-bae6-f82e906ec169/image.png)

출처: https://compmath.korea.ac.kr/deeplearning/_images/diagram-for-general-view-of-artificial-neuron_2.jpg

- 사람 뇌의 **뉴런**을 수학적으로 흉내낸 것

### 다층 퍼셉트론(MLP 멀티 레이어 퍼셉트론)

![](https://velog.velcdn.com/images/soonmac/post/d4d7f568-7c87-4fb9-ad3b-054227f456a9/image.png)


출처 : https://blog.kakaocdn.net/dn/bWGJOk/btqCAPoyI6J/pN7cSTLpzyIX3ekApv040k/img.png

- 위에서 설명한 뉴런 같은 퍼셉트론을 여러 층으로 쌓은 것
- 입력층, 은닉층, 출력층으로 구성됨
    - 입력층 : 각각의 입력을 처리
    - 은닉층 : 복잡한 문제 계산
    - 출력층 : 결과 출력

## 인공신경망은 어떻게 작동하나요?

1. 입력값(x) 받음 → 입력값에 가중치(weight)를 곱하고 편향(bias)을 더함.  $y = Wx + b$ 

> 💡 **가중치(weight)**
- 입력 데이터의 중요도를 조절하는 값 ⇒ **“이 입력이 결과에 얼마나 영향을 미칠까?”**
- 예시 ) 라면을 끓일 때 넣는 물, 라면, 스프, 계란이 맛(결과)에 영향을 줌!
그러나 각 재료의 중요도는 다를 수 밖에 없음
 스프에 중요도(가중치)를 높게 줄 수도 있고, 계란에 상대적으로 낮은 중요도(가중치)를 줄 수도 있다~
    

> 💡 **편향(bias)**
- 만일 입력값이 0일 때 가중치를 아무리 곱해도 결과는 0으로 나옵니다.
- 이걸 방지하기 위해 입력값이 0이어도 어떤 출력을 만들게끔 더해주는 값이 편향!

1. 가중치과 편향이 적용된 계산 결과를 **활성화 함수**(activation function)를 통과시킴
    - 이 과정이 없으면 복잡한 문제를 풀 수가 없어요
2. 출력 값 계산
    - 결과값이 나옵니다.
3. 오차 계산 및 학습
    - 예측 값과 정답의 차이를 계산 (오차) ⇒ **손실 함수**
    - 오차를 최소화하기 위해 가중치와 편향을 조정
    - 이 과정을 여러 번 반복해서 학습함

# 1주차 WIL 딥러닝 이론 

### 활성화 함수

- 입력값을 **비선형적**으로 변환하여 신경망이 더 복잡한 패턴을 학습할 수 있도록 돕는 함수

![](https://velog.velcdn.com/images/soonmac/post/b8c324a0-4cd4-4ce3-a4b0-b8dac179ff6b/image.png)

- **ReLU**: `f(x) = max(0, x)` - 0과 x 사이의 max 값을 반환, 음수는 0으로 출력. 계산이 간단하다.

![](https://velog.velcdn.com/images/soonmac/post/25e2a7b6-97d7-461a-9b3a-988a0977a4c4/image.png)


- **Sigmoid**: `f(x) = 1 / (1 + e^(-x))` - 출력값을 0과 1 사이로 변환 ⇒ 확률 표현하기 적합

### **⚙️ 작동 과정**

![](https://velog.velcdn.com/images/soonmac/post/d21f0745-3140-4d3d-8b4b-b720f1116e15/image.png)


출처 : https://blog.kakaocdn.net/dn/Og5eJ/btsr0sPDvBx/9lmqMnuJJZWQqKxKNCqS3K/img.png

1. 입력 데이터 각 뉴런에 전달 (입력층)
    1. 숫자(벡터) 형태 `[0.2, 0.5, 0.1]`
2. 각 뉴런은 가중치와 편향을 적용해서 활성화 함수로 보냄 (은닉층)
3. 활성화 함수를 통해 출력값을 결정! (출력층)
4. 예측 값과 실제 값(=기대값)의 차이를 계 (손실 계산)
5. 적절한 선을 찾기 위해 가중치와 편향의 값을 조정 하여 다시 1번으로 돌아감 (반복 학습!)

1~3번까지 예측값을 얻어내는 과정 =  **“순전파”**

5번의 오차를 줄이는 과정 = **“역전파”**


-----------------
이렇게 딥러닝과 인공신경망의 동작 원리에 대해 정리해봤다.
이 외에도 딥러닝에 필요한 테크닉에 대해서도 배웠는데 이거는 직접 과제를 해결해보면서 정리해보겠다. 다음주에 따로 포스팅을 하든, 이 포스트에 수정해서 올리든 할 것 같음

지적 언제나 환영합니다^^

#항해99 #항해 플러스 AI 후기 #AI 개발자 #LLM
